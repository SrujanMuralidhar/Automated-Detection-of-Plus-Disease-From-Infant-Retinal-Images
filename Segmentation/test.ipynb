{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image, ImageEnhance\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Predicts the mask and then superposes that on the original image\n",
    "\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "\n",
    "# model = model.build_unet()\n",
    "# model.load_state_dict(torch.load(r'files\\bv_sig_G_clahe.pth', map_location=torch.device('cuda')))\n",
    "# model.eval()\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         output = mask_parse(output)\n",
    "\n",
    "#     return output\n",
    "\n",
    "\n",
    "# def superimpose_mask_on_image(image_path, predicted_mask):\n",
    "#     original_image = Image.open(image_path).convert('RGB').resize((512, 512))\n",
    "    \n",
    "#     # Convert predicted mask to RGBA where the mask is highlighted in red\n",
    "#     mask_rgba = Image.fromarray(predicted_mask * 255).convert(\"RGBA\")\n",
    "#     mask_rgba_np = np.array(mask_rgba)\n",
    "\n",
    "#     # Highlight mask region by making it red\n",
    "#     mask_rgba_np[..., 0] = 255  # Red channel\n",
    "#     mask_rgba_np[..., 1] = 0    # Green channel\n",
    "#     mask_rgba_np[..., 2] = 0    # Blue channel\n",
    "#     mask_rgba_np[..., 3] = (predicted_mask[..., 0] * 128).astype(np.uint8)  # Transparency\n",
    "\n",
    "#     mask_rgba = Image.fromarray(mask_rgba_np)\n",
    "\n",
    "#     # Superimpose mask onto the original image\n",
    "#     blended_image = Image.alpha_composite(original_image.convert(\"RGBA\"), mask_rgba)\n",
    "\n",
    "#     return blended_image\n",
    "\n",
    "\n",
    "\n",
    "# image_path = r'new_data\\test\\image\\3 (2)_0.png'\n",
    "# image_tensor = load_image(image_path)\n",
    "\n",
    "# # Get the predicted mask\n",
    "# predicted_mask = get_prediction(model, image_tensor)\n",
    "\n",
    "# # Superimpose the mask on the original image\n",
    "# superimposed_image = superimpose_mask_on_image(image_path, predicted_mask)\n",
    "\n",
    "# # Save the final superimposed image\n",
    "# superimposed_image.save(f'superimposed_image_new.png')\n",
    "\n",
    "# print(\"Superimposed image saved as 'superimposed_image.png'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the mask for an entire folder\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load model\n",
    "# model = model.build_unet()\n",
    "# model.load_state_dict(torch.load(r'files\\ridge_gabor.pth', map_location=torch.device('cuda')))\n",
    "# model.eval()\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         output = mask_parse(output)\n",
    "#     return output\n",
    "\n",
    "# # Main folder paths\n",
    "# image_folder = r'new_data_ridge\\test\\to_send'  # Folder with images\n",
    "# mask_output_folder = r'output'  # Folder where predicted masks will be saved\n",
    "\n",
    "# # Create output folder if it doesn't exist\n",
    "# if not os.path.exists(mask_output_folder):\n",
    "#     os.mkdir(mask_output_folder)\n",
    "\n",
    "# # Iterate through images in the image folder\n",
    "# for image_name in os.listdir(image_folder):\n",
    "#     image_path = os.path.join(image_folder, image_name)\n",
    "    \n",
    "#     # Load the image and predict the mask\n",
    "#     image_tensor = load_image(image_path)\n",
    "#     predicted_mask = get_prediction(model, image_tensor)\n",
    "    \n",
    "#     # Convert predicted mask to image format for saving\n",
    "#     predicted_mask_image = Image.fromarray((predicted_mask * 255).astype(np.uint8))\n",
    "    \n",
    "#     # Save the predicted mask\n",
    "#     mask_save_path = os.path.join(mask_output_folder, f\"mask_{image_name}\")\n",
    "#     predicted_mask_image.save(mask_save_path)\n",
    "    \n",
    "#     print(f\"Saved mask for {image_name} at {mask_save_path}\")\n",
    "\n",
    "# print(\"Mask generation and saving complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load model\n",
    "# model = model.build_unet()\n",
    "# model.load_state_dict(torch.load(r'files\\bv_no_enhancement_no_aug.pth', map_location=torch.device('cuda')))\n",
    "# model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "# # Load ground truth mask\n",
    "# def load_mask(mask_path):\n",
    "#     mask = Image.open(mask_path).convert('L')  # Assuming mask is grayscale\n",
    "#     mask = mask.resize((512, 512))\n",
    "#     mask = np.stack([mask]*3, axis=-1)  # Convert to 3 channels\n",
    "#     return Image.fromarray(mask)\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         output = mask_parse(output)\n",
    "#     return output\n",
    "\n",
    "# # Concatenate original image, ground truth, and predicted mask with padding in between\n",
    "# def concatenate_images(original_image, ground_truth_mask, predicted_mask, padding=10, padding_color=(255, 255, 255)):\n",
    "#     # Create padding image (gap between images)\n",
    "#     pad = Image.new('RGB', (padding, original_image.height), padding_color)\n",
    "    \n",
    "#     # Create a new image with the correct width to accommodate the 3 images and 2 paddings\n",
    "#     total_width = original_image.width * 3 + padding * 2\n",
    "#     concatenated_image = Image.new('RGB', (total_width, original_image.height))\n",
    "    \n",
    "#     # Paste the original image, ground truth mask, and predicted mask with padding in between\n",
    "#     concatenated_image.paste(original_image, (0, 0))\n",
    "#     concatenated_image.paste(pad, (original_image.width, 0))\n",
    "#     concatenated_image.paste(ground_truth_mask, (original_image.width + padding, 0))\n",
    "#     concatenated_image.paste(pad, (original_image.width * 2 + padding, 0))\n",
    "#     concatenated_image.paste(predicted_mask, (original_image.width * 2 + padding * 2, 0))\n",
    "    \n",
    "#     return concatenated_image\n",
    "\n",
    "# # Main folder paths\n",
    "# image_folder = r'new_data\\test\\image'  # Folder with images\n",
    "# ground_truth_folder = r'new_data\\test\\mask'  # Folder with ground truth masks\n",
    "# output_folder = r'output'  # Folder where concatenated images will be saved\n",
    "\n",
    "# # Create output folder if it doesn't exist\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.mkdir(output_folder)\n",
    "\n",
    "# # Iterate through images in the image folder\n",
    "# for image_name in os.listdir(image_folder):\n",
    "#     image_path = os.path.join(image_folder, image_name)\n",
    "#     ground_truth_path = os.path.join(ground_truth_folder, image_name)  # Assuming same name for ground truth masks\n",
    "    \n",
    "#     # Load the image, ground truth mask, and predict the mask\n",
    "#     image_tensor = load_image(image_path)\n",
    "#     original_image = Image.open(image_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "#     predicted_mask = get_prediction(model, image_tensor)\n",
    "#     predicted_mask_image = Image.fromarray((predicted_mask * 255).astype(np.uint8))  # Convert predicted mask to image format\n",
    "    \n",
    "#     ground_truth_mask = load_mask(ground_truth_path)  # Load ground truth mask\n",
    "    \n",
    "#     # Concatenate images with padding\n",
    "#     concatenated_image = concatenate_images(original_image, ground_truth_mask, predicted_mask_image, padding=20)  # Adjust padding size as needed\n",
    "    \n",
    "#     # Save the concatenated image\n",
    "#     concatenated_save_path = os.path.join(output_folder, f\"concatenated_{image_name}\")\n",
    "#     concatenated_image.save(concatenated_save_path)\n",
    "    \n",
    "#     print(f\"Saved concatenated image for {image_name} at {concatenated_save_path}\")\n",
    "\n",
    "# print(\"Concatenation and saving complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load models\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "# bv_model.eval()\n",
    "\n",
    "# ridge_model = model.build_unet()\n",
    "# ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "# ridge_model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0)\n",
    "#     return image\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "#     # Initialize the combined mask with 3 channels (for RGB)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "#     # Color the blood vessel mask in red\n",
    "#     combined_mask[bv_mask == 1] = [255, 0, 0]  # Red channel\n",
    "    \n",
    "#     # Color the ridge mask in blue\n",
    "#     combined_mask[ridge_mask == 1] = [0, 0, 255]  # Blue channel\n",
    "    \n",
    "#     # Convert original image to NumPy\n",
    "#     original_image_np = np.array(original_image)\n",
    "    \n",
    "#     # Superpose the masks on the original image\n",
    "#     superposed_image = original_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Main folder paths\n",
    "# image_folder = r'Data_BV\\test_image'  # Folder with images\n",
    "# output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# # Create output folder if it doesn't exist\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.mkdir(output_folder)\n",
    "\n",
    "# # Iterate through images in the image folder\n",
    "# for image_name in os.listdir(image_folder):\n",
    "#     image_path = os.path.join(image_folder, image_name)\n",
    "    \n",
    "#     # Load the image and predict masks for blood vessel and ridge\n",
    "#     image_tensor = load_image(image_path)\n",
    "#     original_image = Image.open(image_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "    \n",
    "#     bv_mask = get_prediction(bv_model, image_tensor)  # Blood vessel mask\n",
    "#     ridge_mask = get_prediction(ridge_model, image_tensor)  # Ridge mask\n",
    "    \n",
    "#     # Superpose the masks onto the original image\n",
    "#     superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "    \n",
    "#     # Save the superposed image\n",
    "#     superposed_save_path = os.path.join(output_folder, f\"superposed_{image_name}\")\n",
    "#     superposed_image.save(superposed_save_path)\n",
    "    \n",
    "#     print(f\"Saved superposed image for {image_name} at {superposed_save_path}\")\n",
    "\n",
    "# print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "# from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load models\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "# bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "# bv_model.eval()\n",
    "\n",
    "# ridge_model = model.build_unet()\n",
    "# ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "# ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "# ridge_model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         image = image.resize((512, 512))\n",
    "#         image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "#         return image\n",
    "    \n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "#     # Initialize the combined mask with 3 channels (for RGB)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "#     # Color the blood vessel mask in red\n",
    "#     combined_mask[bv_mask == 1] = [255, 0, 0]  # Red channel\n",
    "    \n",
    "#     # Color the ridge mask in blue\n",
    "#     combined_mask[ridge_mask == 1] = [0, 0, 255]  # Blue channel\n",
    "    \n",
    "#     # Convert original image to NumPy\n",
    "#     original_image_np = np.array(original_image)\n",
    "    \n",
    "#     # Superpose the masks on the original image\n",
    "#     superposed_image = original_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Function to recursively process all images in subfolders\n",
    "# def process_folders(bv_input_folder, ridge_input_folder, output_folder):\n",
    "#     # Create output folder if it doesn't exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     # List all items in the blood vessel folder\n",
    "#     bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "#     # Use tqdm for progress bar when processing the items\n",
    "#     for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "#         bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "#         ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "#         output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "#         if os.path.isdir(bv_item_path):\n",
    "#             # If the item is a subfolder, recursively process it\n",
    "#             process_folders(bv_item_path, ridge_item_path, output_item_path)\n",
    "#         else:\n",
    "#             # If the item is an image, check if ridge image exists\n",
    "#             if not os.path.exists(ridge_item_path):\n",
    "#                 print(f\"Ridge image not found for {bv_item}. Skipping.\")\n",
    "#                 continue\n",
    "            \n",
    "#             bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "#             ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "            \n",
    "#             original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "#             bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "#             ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "#             # Superpose the masks onto the original image\n",
    "#             superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "#             # Save the superposed image\n",
    "#             output_folder_path = os.path.dirname(output_item_path)\n",
    "#             if not os.path.exists(output_folder_path):\n",
    "#                 os.makedirs(output_folder_path)\n",
    "#             superposed_image.save(output_item_path)\n",
    "            \n",
    "#             print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# # Main input and output folder paths\n",
    "\n",
    "# bv_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data'  # Folder for blood vessel images\n",
    "\n",
    "# ridge_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_gabor'  # Folder for ridge images\n",
    "\n",
    "# main_output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# # Start processing the main folder\n",
    "# process_folders(bv_input_folder, ridge_input_folder, main_output_folder)\n",
    "\n",
    "# print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load models\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "ridge_model = model.build_unet()\n",
    "ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "ridge_model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "        return image\n",
    "    \n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "def sigmoid_correction(image, k=10, x0=0.5):\n",
    "    # Normalize the image\n",
    "    normalized_img = image / 255.0\n",
    "    # Apply the sigmoid function\n",
    "    sigmoid_img = 1 / (1 + np.exp(-k * (normalized_img - x0)))\n",
    "    # Scale back to original range\n",
    "    corrected_img = (sigmoid_img * 255).astype(np.uint8)\n",
    "    return corrected_img\n",
    "\n",
    "\n",
    "def adaptive_sigmoid(image):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    radius = image.shape[1]//2\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "    hist = cv2.calcHist([image], [1], mask, [256], [0, 256])\n",
    "    # Calculate cumulative distribution function (CDF)\n",
    "    cdf = hist.cumsum()\n",
    "    # Normalize CDF\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    # Find the intensity level where CDF reaches 50% of the total pixel count\n",
    "    total_pixels = cdf[-1]\n",
    "    x_0 = np.searchsorted(cdf, total_pixels * 0.5)/255\n",
    "    k = 15\n",
    "    sig = sigmoid_correction(image,k,x_0)\n",
    "    return sig\n",
    "\n",
    "def apply_hist_eq(image):\n",
    "    # Split the image into its respective channels\n",
    "    channels = cv2.split(image)\n",
    "    \n",
    "    # Apply histogram equalization on each channel\n",
    "    equalized_channels = [cv2.equalizeHist(channel) for channel in channels]\n",
    "    \n",
    "    # Merge the equalized channels back into a single image\n",
    "    equalized_image = cv2.merge(equalized_channels)\n",
    "    \n",
    "    return equalized_image\n",
    "\n",
    "# Superpose masks on the original image\n",
    "# Superpose masks on the original image with sigmoid correction\n",
    "def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "    # Convert original image to NumPy\n",
    "    original_image_np = np.array(original_image)\n",
    "    \n",
    "    # Apply sigmoid correction to the original image\n",
    "    corrected_image_np = adaptive_sigmoid(original_image_np)\n",
    "    \n",
    "    # Initialize the combined mask with 3 channels (for RGB)\n",
    "    combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # COLOR coding for the MASKS\n",
    "    #-----------------------------------------------------------------------------\n",
    "    combined_mask[bv_mask == 1] = [179, 2, 2]  \n",
    "    combined_mask[ridge_mask == 1] = [25, 10, 242]  \n",
    "    #------------------------------------------------------------------------------\n",
    "    # Superpose the masks on the sigmoid-corrected original image\n",
    "    superposed_image = corrected_image_np.copy()\n",
    "    mask_indices = combined_mask > 0\n",
    "    superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "    return Image.fromarray(superposed_image)\n",
    "\n",
    "# Function to recursively process all images in subfolders\n",
    "def process_folders(bv_input_folder, ridge_input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # List all items in the blood vessel folder\n",
    "    bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "    # Use tqdm for progress bar when processing the items\n",
    "    for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "        bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "        ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "        output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "        if os.path.isdir(bv_item_path):\n",
    "            # If the item is a subfolder, recursively process it\n",
    "            process_folders(bv_item_path, ridge_item_path, output_item_path)\n",
    "        else:\n",
    "            # If the item is an image, check if ridge image exists\n",
    "            if not os.path.exists(ridge_item_path):\n",
    "                print(f\"Ridge image not found for {bv_item}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "            ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "            \n",
    "            original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "            bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "            ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "            # Superpose the masks onto the original image\n",
    "            superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "            # Save the superposed image\n",
    "            output_folder_path = os.path.dirname(output_item_path)\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            superposed_image.save(output_item_path)\n",
    "            \n",
    "            # print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# Main input and output folder paths\n",
    "\n",
    "bv_input_folder = r'Data_BV\\train_images'  # Folder for blood vessel images\n",
    "\n",
    "ridge_input_folder = r'Data_Ridge'  # Folder for ridge images\n",
    "\n",
    "main_output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# Start processing the main folder\n",
    "process_folders(bv_input_folder, ridge_input_folder, main_output_folder)\n",
    "\n",
    "print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "# import cv2\n",
    "# from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load models\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'files\\bv_perCHistEq_kaggle_data.pth', map_location=torch.device('cuda')))\n",
    "# bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "# bv_model.eval()\n",
    "\n",
    "# ridge_model = model.build_unet()\n",
    "# ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "# ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "# ridge_model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')): \n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         image = image.resize((512, 512))\n",
    "#         image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "#         return image\n",
    "    \n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "#     # Convert original image to NumPy\n",
    "#     original_image_np = np.array(original_image)\n",
    "    \n",
    "#     # Apply sigmoid correction to the original image\n",
    "#     corrected_image_np = adaptive_sigmoid(original_image_np)\n",
    "    \n",
    "#     # Initialize the combined mask with 3 channels (for RGB)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "#     # COLOR coding for the MASKS\n",
    "#     #-----------------------------------------------------------------------------\n",
    "#     combined_mask[bv_mask == 1] = [179, 2, 2]  \n",
    "#     combined_mask[ridge_mask == 1] = [25, 10, 242]  \n",
    "#     #------------------------------------------------------------------------------\n",
    "#     # Superpose the masks on the sigmoid-corrected original image\n",
    "#     superposed_image = corrected_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "    \n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Function to recursively process all images in subfolders\n",
    "# def process_folders(bv_input_folder, ridge_input_folder, original_image_folder, output_folder):\n",
    "#     # Create output folder if it doesn't exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     # List all items in the blood vessel folder\n",
    "#     bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "#     # Use tqdm for progress bar when processing the items\n",
    "#     for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "#         bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "#         ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "#         original_image_path = os.path.join(original_image_folder, bv_item)  # Get the original image\n",
    "#         output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "#         if os.path.isdir(bv_item_path):\n",
    "#             # If the item is a subfolder, recursively process it\n",
    "#             process_folders(bv_item_path, ridge_item_path, original_image_path, output_item_path)\n",
    "#         else:\n",
    "#             # If the item is an image, check if ridge and original images exist\n",
    "#             if not os.path.exists(ridge_item_path) or not os.path.exists(original_image_path):\n",
    "#                 print(f\"Ridge or original image not found for {bv_item}. Skipping.\")\n",
    "#                 continue\n",
    "            \n",
    "#             bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "#             ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "#             original_image = Image.open(original_image_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "#             bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "#             ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "#             # Superpose the masks onto the original image\n",
    "#             superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "#             # Save the superposed image\n",
    "#             output_folder_path = os.path.dirname(output_item_path)\n",
    "#             if not os.path.exists(output_folder_path):\n",
    "#                 os.makedirs(output_folder_path)\n",
    "#             superposed_image.save(output_item_path)\n",
    "            \n",
    "#             # print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# # Main input and output folder paths\n",
    "\n",
    "# bv_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_histEq'  # Folder for blood vessel images\n",
    "# ridge_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_gabor'  # Folder for ridge images\n",
    "# original_image_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data'  # Folder for original images\n",
    "# main_output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# # Start processing the main folder\n",
    "# process_folders(bv_input_folder, ridge_input_folder, original_image_folder, main_output_folder)\n",
    "\n",
    "# print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import os\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load models\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "ridge_model = model.build_unet()\n",
    "ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "ridge_model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "        return image\n",
    "\n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "# Concatenate masks with the original image\n",
    "def concat_masks(original_image, bv_mask, ridge_mask):\n",
    "    # Convert masks to images (grayscale masks)\n",
    "    bv_mask_image = Image.fromarray(bv_mask * 255).convert('L').resize((512, 512))\n",
    "    ridge_mask_image = Image.fromarray(ridge_mask * 255).convert('L').resize((512, 512))\n",
    "    \n",
    "    # Concatenate original, blood vessel mask, and ridge mask side by side\n",
    "    concatenated_image = Image.new('RGB', (original_image.width + bv_mask_image.width + ridge_mask_image.width, 512))\n",
    "    concatenated_image.paste(original_image, (0, 0))\n",
    "    concatenated_image.paste(ridge_mask_image.convert('RGB'), (512, 0))  # Convert mask to RGB for concatenation\n",
    "    concatenated_image.paste(bv_mask_image.convert('RGB'), (1024, 0))  # Convert mask to RGB for concatenation\n",
    "   \n",
    "    \n",
    "    return concatenated_image\n",
    "\n",
    "# Function to recursively process all images in subfolders\n",
    "def process_folders(bv_input_folder, ridge_input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # List all items in the blood vessel folder\n",
    "    bv_items = os.listdir(bv_input_folder)\n",
    "    \n",
    "    # Use tqdm for progress bar when processing the items\n",
    "    for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "        bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "        ridge_item_path = os.path.join(ridge_input_folder, bv_item)  # Assume ridge folder has the same structure\n",
    "        output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "        if os.path.isdir(bv_item_path):\n",
    "            # If the item is a subfolder, recursively process it\n",
    "            process_folders(bv_item_path, ridge_item_path, output_item_path)\n",
    "        else:\n",
    "            # If the item is an image, check if ridge image exists\n",
    "            if not os.path.exists(ridge_item_path):\n",
    "                print(f\"Ridge image not found for {bv_item}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "            ridge_image_tensor = load_image(ridge_item_path)  # Ridge image\n",
    "            \n",
    "            original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "            \n",
    "            bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "            ridge_mask = get_prediction(ridge_model, ridge_image_tensor)  # Ridge mask\n",
    "            \n",
    "            # Concatenate the masks with the original image\n",
    "            concatenated_image = concat_masks(original_image, bv_mask, ridge_mask)\n",
    "            \n",
    "            # Save the concatenated image\n",
    "            output_folder_path = os.path.dirname(output_item_path)\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            concatenated_image.save(output_item_path)\n",
    "            \n",
    "            print(f\"Saved concatenated image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# Main input and output folder paths\n",
    "\n",
    "bv_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data'  # Folder for blood vessel images\n",
    "ridge_input_folder = r'C:\\Users\\xerom\\Documents\\CAPSTONE\\Classification\\Data_gabor'  # Folder for ridge images\n",
    "main_output_folder = r'output'  # Folder where concatenated images will be saved\n",
    "\n",
    "# Start processing the main folder\n",
    "process_folders(bv_input_folder, ridge_input_folder, main_output_folder)\n",
    "\n",
    "print(\"Concatenation and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import cv2\n",
    "\n",
    "# # Load models\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'files\\bv_no_enhancement.pth', map_location=torch.device('cuda')))\n",
    "# bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "# bv_model.eval()\n",
    "\n",
    "# ridge_model = model.build_unet()\n",
    "# ridge_model.load_state_dict(torch.load(r'files\\gabor_ridge_aug.pth', map_location=torch.device('cuda')))\n",
    "# ridge_model = ridge_model.cuda()  # Load model on GPU if available\n",
    "# ridge_model.eval()\n",
    "\n",
    "# # Image transformations\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     image = image.resize((512, 512))\n",
    "#     image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "#     return image\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "# # Sigmoid correction functions\n",
    "# def sigmoid_correction(image, k=10, x0=0.5):\n",
    "#     normalized_img = image / 255.0\n",
    "#     sigmoid_img = 1 / (1 + np.exp(-k * (normalized_img - x0)))\n",
    "#     corrected_img = (sigmoid_img * 255).astype(np.uint8)\n",
    "#     return corrected_img\n",
    "\n",
    "# def adaptive_sigmoid(image):\n",
    "#     mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "#     center = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "#     radius = image.shape[1] // 2\n",
    "#     cv2.circle(mask, center, radius, 255, -1)\n",
    "#     hist = cv2.calcHist([image], [1], mask, [256], [0, 256])\n",
    "#     cdf = hist.cumsum()\n",
    "#     total_pixels = cdf[-1]\n",
    "#     x_0 = np.searchsorted(cdf, total_pixels * 0.5) / 255\n",
    "#     k = 15\n",
    "#     sig = sigmoid_correction(image, k, x_0)\n",
    "#     return sig\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask, ridge_mask):\n",
    "#     original_image_np = np.array(original_image)\n",
    "#     corrected_image_np = adaptive_sigmoid(original_image_np)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "#     combined_mask[bv_mask == 1] = [179, 2, 2]  \n",
    "#     combined_mask[ridge_mask == 1] = [25, 10, 242]\n",
    "#     superposed_image = corrected_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Function to process a single image\n",
    "# def process_single_image(bv_image_path, ridge_image_path, output_path):\n",
    "#     bv_image_tensor = load_image(bv_image_path)\n",
    "#     ridge_image_tensor = load_image(ridge_image_path)\n",
    "#     original_image = Image.open(bv_image_path).convert('RGB').resize((512, 512))\n",
    "\n",
    "#     bv_mask = get_prediction(bv_model, bv_image_tensor)\n",
    "#     ridge_mask = get_prediction(ridge_model, ridge_image_tensor)\n",
    "\n",
    "#     superposed_image = superpose_masks(original_image, bv_mask, ridge_mask)\n",
    "#     superposed_image.save(output_path)\n",
    "#     print(f\"Saved superposed image at {output_path}\")\n",
    "\n",
    "# # Example usage\n",
    "# bv_image_path = r'Data_BV\\train_images\\Img1 (17).png'\n",
    "# ridge_image_path = r'new_data\\train\\image\\Img1 (17)_0.png'\n",
    "# output_path = r'path_to_output_image.jpg'\n",
    "# process_single_image(bv_image_path, ridge_image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import os\n",
    "from tqdm import tqdm  # For progress bar\n",
    "from skimage.morphology import skeletonize  # For thinning masks\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load blood vessel model\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "        return image\n",
    "\n",
    "def thin_mask(mask):\n",
    "    return skeletonize(mask).astype(np.uint8)\n",
    "\n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "# Superpose masks on the original image\n",
    "def superpose_masks(original_image, bv_mask):\n",
    "    # Initialize the combined mask with 3 channels (for RGB)\n",
    "    combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Color the blood vessel mask in red\n",
    "    combined_mask[bv_mask == 1] = [255, 0, 0]  # Red channel\n",
    "\n",
    "    # Convert original image to NumPy\n",
    "    original_image_np = np.array(original_image)\n",
    "\n",
    "    # Superpose the masks on the original image\n",
    "    superposed_image = original_image_np.copy()\n",
    "    mask_indices = combined_mask > 0\n",
    "    superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "\n",
    "    return Image.fromarray(superposed_image)\n",
    "\n",
    "# Function to recursively process all images in subfolders\n",
    "def process_folders(bv_input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # List all items in the blood vessel folder\n",
    "    bv_items = os.listdir(bv_input_folder)\n",
    "\n",
    "    # Use tqdm for progress bar when processing the items\n",
    "    for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "        bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "        output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "        if os.path.isdir(bv_item_path):\n",
    "            # If the item is a subfolder, recursively process it\n",
    "            process_folders(bv_item_path, output_item_path)\n",
    "        else:\n",
    "            # If the item is an image\n",
    "            bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "\n",
    "            original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "\n",
    "            bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "\n",
    "            # Superpose the mask onto the original image\n",
    "            superposed_image = superpose_masks(original_image, bv_mask)\n",
    "\n",
    "            # Save the superposed image\n",
    "            output_folder_path = os.path.dirname(output_item_path)\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            superposed_image.save(output_item_path)\n",
    "\n",
    "            # print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# Main input and output folder paths\n",
    "\n",
    "bv_input_folder = r\"C:\\Users\\xerom\\Documents\\CAPSTONE\\CONFERENCE_PAPER\\Classification\\Dataset_gC\"  # Folder for blood vessel images\n",
    "\n",
    "main_output_folder = r'output'  # Folder where superposed images will be saved\n",
    "\n",
    "# Start processing the main folder\n",
    "process_folders(bv_input_folder, main_output_folder)\n",
    "\n",
    "print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xerom\\AppData\\Local\\Temp\\ipykernel_2624\\2873687532.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bv_model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe.pth', map_location=torch.device('cuda')))\n",
      "Processing Folders: 100%|| 300/300 [00:32<00:00,  9.20it/s]\n",
      "Processing Folders: 100%|| 300/300 [00:32<00:00,  9.22it/s]\n",
      "Processing Folders: 100%|| 300/300 [00:32<00:00,  9.24it/s]\n",
      "Processing Folders: 100%|| 3/3 [01:37<00:00, 32.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superposition and saving complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# With thining\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import os\n",
    "from tqdm import tqdm  # For progress bar\n",
    "from skimage.morphology import skeletonize  # For thinning masks\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load blood vessel model\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "bv_model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((512, 512))\n",
    "        image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "        return image\n",
    "\n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        return output\n",
    "\n",
    "# Thin the mask\n",
    "def thin_mask(mask):\n",
    "    return skeletonize(mask).astype(np.uint8)\n",
    "\n",
    "# Superpose masks on the original image\n",
    "def superpose_masks(original_image, bv_mask):\n",
    "    # Initialize the combined mask with 3 channels (for RGB)\n",
    "    combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Color the blood vessel mask in red\n",
    "    combined_mask[bv_mask == 1] = [57, 255, 20]  # Red channel\n",
    "\n",
    "    # Convert original image to NumPy\n",
    "    original_image_np = np.array(original_image)\n",
    "\n",
    "    # Superpose the masks on the original image\n",
    "    superposed_image = original_image_np.copy()\n",
    "    mask_indices = combined_mask > 0\n",
    "    superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "\n",
    "    return Image.fromarray(superposed_image)\n",
    "\n",
    "# Function to recursively process all images in subfolders\n",
    "def process_folders(bv_input_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # List all items in the blood vessel folder\n",
    "    bv_items = os.listdir(bv_input_folder)\n",
    "\n",
    "    # Use tqdm for progress bar when processing the items\n",
    "    for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "        bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "        output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "        if os.path.isdir(bv_item_path):\n",
    "            # If the item is a subfolder, recursively process it\n",
    "            process_folders(bv_item_path, output_item_path)\n",
    "        else:\n",
    "            # If the item is an image\n",
    "            bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "\n",
    "            original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "\n",
    "            bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "            bv_mask = thin_mask(bv_mask)  # Thin the mask\n",
    "\n",
    "            # Superpose the mask onto the original image\n",
    "            superposed_image = superpose_masks(original_image, bv_mask)\n",
    "\n",
    "            # Save the superposed image\n",
    "            output_folder_path = os.path.dirname(output_item_path)\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            superposed_image.save(output_item_path)\n",
    "\n",
    "            # print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# Main input and output folder paths\n",
    "\n",
    "bv_input_folder = r\"C:\\Users\\xerom\\Documents\\CAPSTONE\\CONFERENCE_PAPER\\Classification\\Dataset_gC\"  # Folder for blood vessel images\n",
    "\n",
    "main_output_folder = r'output_thinned'  # Folder where superposed images will be saved\n",
    "\n",
    "# Start processing the main folder\n",
    "process_folders(bv_input_folder, main_output_folder)\n",
    "\n",
    "print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xerom\\AppData\\Local\\Temp\\ipykernel_8880\\901033562.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bv_model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe.pth', map_location=torch.device('cuda')))\n",
      "Processing Folders: 100%|| 300/300 [00:39<00:00,  7.56it/s]\n",
      "Processing Folders: 100%|| 300/300 [00:40<00:00,  7.46it/s]\n",
      "Processing Folders: 100%|| 300/300 [00:40<00:00,  7.43it/s]\n",
      "Processing Folders: 100%|| 3/3 [02:00<00:00, 40.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superposition and saving complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import model\n",
    "# import os\n",
    "# from tqdm import tqdm  # For progress bar\n",
    "# from skimage.morphology import skeletonize, thin  # For thinning masks\n",
    "\n",
    "# # Parse mask for saving\n",
    "# def mask_parse(mask):\n",
    "#     mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "#     mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "#     return mask\n",
    "\n",
    "# # Load blood vessel model\n",
    "# bv_model = model.build_unet()\n",
    "# bv_model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe.pth', map_location=torch.device('cuda')))\n",
    "# bv_model = bv_model.cuda()  # Load model on GPU if available\n",
    "# bv_model.eval()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Load and resize the image\n",
    "# def load_image(image_path):\n",
    "#     if image_path.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         image = image.resize((512, 512))\n",
    "#         image = transform(image).unsqueeze(0).cuda()  # Ensure tensor is on GPU\n",
    "#         return image\n",
    "\n",
    "# # Get mask prediction\n",
    "# def get_prediction(model, image_tensor):\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "#         output = torch.sigmoid(output)\n",
    "#         output = output[0].cpu().numpy()  # Move to CPU for further processing\n",
    "#         output = np.squeeze(output, axis=0)\n",
    "#         output = output > 0.5\n",
    "#         output = np.array(output, dtype=np.uint8)\n",
    "#         return output\n",
    "\n",
    "# # Thin the mask with controllable amount\n",
    "# def thin_mask(mask, thinning_iterations=1):\n",
    "#     if thinning_iterations > 0:\n",
    "#         return thin(mask, thinning_iterations).astype(np.uint8)\n",
    "#     else:\n",
    "#         return mask\n",
    "\n",
    "# # Superpose masks on the original image\n",
    "# def superpose_masks(original_image, bv_mask):\n",
    "#     # Initialize the combined mask with 3 channels (for RGB)\n",
    "#     combined_mask = np.zeros((bv_mask.shape[0], bv_mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "#     # Color the blood vessel mask in red\n",
    "#     combined_mask[bv_mask == 1] = [255, 0, 0]  # Red channel\n",
    "\n",
    "#     # Convert original image to NumPy\n",
    "#     original_image_np = np.array(original_image)\n",
    "\n",
    "#     # Superpose the masks on the original image\n",
    "#     superposed_image = original_image_np.copy()\n",
    "#     mask_indices = combined_mask > 0\n",
    "#     superposed_image[mask_indices] = combined_mask[mask_indices]\n",
    "\n",
    "#     return Image.fromarray(superposed_image)\n",
    "\n",
    "# # Function to recursively process all images in subfolders\n",
    "# def process_folders(bv_input_folder, output_folder, thinning_iterations=1):\n",
    "#     # Create output folder if it doesn't exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     # List all items in the blood vessel folder\n",
    "#     bv_items = os.listdir(bv_input_folder)\n",
    "\n",
    "#     # Use tqdm for progress bar when processing the items\n",
    "#     for bv_item in tqdm(bv_items, desc=\"Processing Folders\"):\n",
    "#         bv_item_path = os.path.join(bv_input_folder, bv_item)\n",
    "#         output_item_path = os.path.join(output_folder, bv_item)\n",
    "\n",
    "#         if os.path.isdir(bv_item_path):\n",
    "#             # If the item is a subfolder, recursively process it\n",
    "#             process_folders(bv_item_path, output_item_path, thinning_iterations)\n",
    "#         else:\n",
    "#             # If the item is an image\n",
    "#             bv_image_tensor = load_image(bv_item_path)  # Blood vessel image\n",
    "\n",
    "#             original_image = Image.open(bv_item_path).convert('RGB').resize((512, 512))  # Load original image\n",
    "\n",
    "#             bv_mask = get_prediction(bv_model, bv_image_tensor)  # Blood vessel mask\n",
    "#             bv_mask = thin_mask(bv_mask, thinning_iterations)  # Thin the mask\n",
    "\n",
    "#             # Superpose the mask onto the original image\n",
    "#             superposed_image = superpose_masks(original_image, bv_mask)\n",
    "\n",
    "#             # Save the superposed image\n",
    "#             output_folder_path = os.path.dirname(output_item_path)\n",
    "#             if not os.path.exists(output_folder_path):\n",
    "#                 os.makedirs(output_folder_path)\n",
    "#             superposed_image.save(output_item_path)\n",
    "\n",
    "#             # print(f\"Saved superposed image for {bv_item} at {output_item_path}\")\n",
    "\n",
    "# # Main input and output folder paths\n",
    "\n",
    "# bv_input_folder = r\"C:\\Users\\xerom\\Documents\\CAPSTONE\\CONFERENCE_PAPER\\Classification\\Dataset_gC\"  # Folder for blood vessel images\n",
    "\n",
    "# main_output_folder = r'output_controlled_thin'  # Folder where superposed images will be saved\n",
    "\n",
    "# thinning_iterations = 4  # Control the amount of thinning (0 for no thinning)\n",
    "\n",
    "# # Start processing the main folder\n",
    "# process_folders(bv_input_folder, main_output_folder, thinning_iterations)\n",
    "\n",
    "# print(\"Superposition and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xerom\\AppData\\Local\\Temp\\ipykernel_2624\\2540109619.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bv_model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe.pth', map_location=torch.device('cuda')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinned blood vessel segmentation mask saved at bv_mask_thinned.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import cv2\n",
    "from skimage.morphology import thin  # For thinning the mask\n",
    "\n",
    "# Load U-Net model for blood vessel segmentation\n",
    "bv_model = model.build_unet()\n",
    "bv_model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe.pth', map_location=torch.device('cuda')))\n",
    "bv_model = bv_model.cuda()\n",
    "bv_model.eval()\n",
    "\n",
    "# Define image transformation\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "def apply_clahe(image):\n",
    "    \"\"\"Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance contrast.\"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)  # Convert to LAB color space\n",
    "    l, a, b = cv2.split(lab)  # Split LAB channels\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))  # Create CLAHE object\n",
    "    l = clahe.apply(l)  # Apply CLAHE to L-channel\n",
    "    lab = cv2.merge((l, a, b))  # Merge channels back\n",
    "    enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)  # Convert back to RGB\n",
    "    return enhanced_image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Load an image, extract the green channel, apply CLAHE, and prepare for model input.\"\"\"\n",
    "    image = cv2.imread(image_path)  # Read image using OpenCV\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "    green_channel = image[:, :, 1]  # Extract the green channel\n",
    "    enhanced_image = apply_clahe(cv2.merge([green_channel, green_channel, green_channel]))  # Apply CLAHE\n",
    "    resized_image = cv2.resize(enhanced_image, (512, 512))  # Resize to match U-Net input size\n",
    "\n",
    "    image_tensor = transform(resized_image).unsqueeze(0).cuda()  # Convert to tensor and move to GPU\n",
    "    return image_tensor, resized_image  # Return tensor and enhanced image for visualization\n",
    "\n",
    "def get_bv_mask(image_tensor, thinning_iterations=4):\n",
    "    \"\"\"Generate blood vessel segmentation mask using the U-Net model and apply thinning.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = bv_model(image_tensor)\n",
    "        output = torch.sigmoid(output)  # Apply sigmoid activation\n",
    "        output = output[0].cpu().numpy()  # Move to CPU\n",
    "        output = np.squeeze(output, axis=0)  # Remove batch dimension\n",
    "        mask = (output > 0.5).astype(np.uint8)  # Convert to binary mask\n",
    "\n",
    "        # Apply thinning to the mask\n",
    "        for _ in range(thinning_iterations):\n",
    "            mask = thin(mask).astype(np.uint8)  # Thin the mask for the specified iterations\n",
    "\n",
    "    return mask\n",
    "\n",
    "def save_mask(mask, save_path):\n",
    "    \"\"\"Save the segmentation mask as an image.\"\"\"\n",
    "    mask = (mask * 255).astype(np.uint8)  # Convert binary mask to 8-bit image\n",
    "    cv2.imwrite(save_path, mask)  # Save the mask\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\xerom\\Documents\\CAPSTONE\\CONFERENCE_PAPER\\Dataset\\No Plus\\FHPL_04-22_20220505131032_20220505131032_Image_03_0035_2022-05-05_13-11-40-732_1526.png\" # Path to the input image\n",
    "output_mask_path = \"bv_mask_thinned.png\"  # Path to save the thinned mask\n",
    "\n",
    "image_tensor, enhanced_image = preprocess_image(image_path)  # Preprocess image\n",
    "bv_mask = get_bv_mask(image_tensor, thinning_iterations=4)  # Get blood vessel segmentation mask and apply thinning\n",
    "save_mask(bv_mask, output_mask_path)  # Save thinned mask\n",
    "\n",
    "print(f\"Thinned blood vessel segmentation mask saved at {output_mask_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
