{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model\n",
    "import os\n",
    "\n",
    "# Parse mask for saving\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)  # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (512, 512, 3)\n",
    "    return mask\n",
    "\n",
    "# Load model and move to CUDA if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.build_unet()\n",
    "model.load_state_dict(torch.load(r'Models\\bv_mask_gC_clahe_added.pth', map_location=device))\n",
    "model.eval().to(device)  # Move model to GPU\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load and resize the image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((512, 512))\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Move to GPU\n",
    "    return image\n",
    "\n",
    "# Get mask prediction\n",
    "def get_prediction(model, image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[0].cpu().numpy()  # Move back to CPU for processing\n",
    "        output = np.squeeze(output, axis=0)\n",
    "        output = output > 0.5\n",
    "        output = np.array(output, dtype=np.uint8)\n",
    "        output = mask_parse(output)\n",
    "    return output\n",
    "\n",
    "# Superimpose the mask on the original image\n",
    "def superimpose_mask(original_image, mask):\n",
    "    # Convert the original image from tensor to numpy array\n",
    "    original_image = original_image.squeeze(0).permute(1, 2, 0).cpu().numpy()  # Convert to (H, W, C)\n",
    "    original_image = (original_image * 255).astype(np.uint8)  # Scale back to 0-255\n",
    "    original_image_pil = Image.fromarray(original_image)\n",
    "\n",
    "    # Convert mask to PIL Image\n",
    "    mask_image = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "\n",
    "    # Blend the original image with the mask\n",
    "    blended_image = Image.blend(original_image_pil, mask_image, alpha=0.5)  # Adjust alpha for transparency\n",
    "    return blended_image\n",
    "\n",
    "# Process images in the folder and subfolders\n",
    "def process_images_in_folder(image_folder, mask_output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(mask_output_folder):\n",
    "        os.makedirs(mask_output_folder)\n",
    "\n",
    "    for root, dirs, files in os.walk(image_folder):\n",
    "        # Create corresponding subfolders in the output directory\n",
    "        for dir_name in dirs:\n",
    "            output_subfolder = os.path.join(mask_output_folder, os.path.relpath(os.path.join(root, dir_name), image_folder))\n",
    "            if not os.path.exists(output_subfolder):\n",
    "                os.makedirs(output_subfolder)\n",
    "\n",
    "        # Process image files in the current folder\n",
    "        for file_name in files:\n",
    "            image_path = os.path.join(root, file_name)\n",
    "            \n",
    "            # Load the image and predict the mask\n",
    "            original_image_tensor = load_image(image_path)\n",
    "            predicted_mask = get_prediction(model, original_image_tensor)\n",
    "            \n",
    "            # Superimpose the mask on the original image\n",
    "            blended_image = superimpose_mask(original_image_tensor, predicted_mask)\n",
    "            \n",
    "            # Save the blended image\n",
    "            rel_path = os.path.relpath(image_path, image_folder)\n",
    "            blended_save_path = os.path.join(mask_output_folder, f\"blended_{rel_path}\")\n",
    "            \n",
    "            blended_save_dir = os.path.dirname(blended_save_path)\n",
    "            if not os.path.exists(blended_save_dir):\n",
    "                os.makedirs(blended_save_dir)\n",
    "            \n",
    "            blended_image.save(blended_save_path)\n",
    "            \n",
    "            print(f\"Saved blended image for {file_name} at {blended_save_path}\")\n",
    "\n",
    "# Main folder paths\n",
    "image_folder = r'new_data_ridge\\test\\to_send'  # Root folder with subfolders and images\n",
    "mask_output_folder = r'output'  # Root output folder where predicted masks will be saved\n",
    "\n",
    "# Process all images in the folder and subfolders\n",
    "process_images_in_folder(image_folder, mask_output_folder)\n",
    "\n",
    "print(\"Mask generation, superimposition, and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def apply_clahe(image):\n",
    "    \"\"\" Apply CLAHE on the green channel \"\"\"\n",
    "    green_channel = image[:, :, 1]  # Extracting the green channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    green_clahe = clahe.apply(green_channel)\n",
    "    # image[:, :, 1] = green_clahe\n",
    "    # return image\n",
    "    return green_clahe\n",
    "\n",
    "def process_images(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Apply CLAHE to all images in the folder structure and save them to the output folder.\n",
    "    \n",
    "    Parameters:\n",
    "        input_folder (str): Path to the folder containing the images.\n",
    "        output_folder (str): Path to the folder where processed images will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for subdir, _, files in os.walk(input_folder):\n",
    "        # Create the corresponding subdirectory in the output folder\n",
    "        relative_path = os.path.relpath(subdir, input_folder)\n",
    "        output_subdir = os.path.join(output_folder, relative_path)\n",
    "        if not os.path.exists(output_subdir):\n",
    "            os.makedirs(output_subdir)\n",
    "\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            output_file_path = os.path.join(output_subdir, file)\n",
    "\n",
    "            try:\n",
    "                # Open the image using PIL and convert it to a NumPy array\n",
    "                img = Image.open(file_path).convert(\"RGB\")\n",
    "                img = np.array(img)\n",
    "\n",
    "                # Apply CLAHE\n",
    "                processed_img = apply_clahe(img)\n",
    "\n",
    "                # Convert back to an image and save\n",
    "                processed_img = Image.fromarray(processed_img)\n",
    "                processed_img.save(output_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = r\"C:\\Users\\xerom\\Documents\\CAPSTONE\\CONFERENCE_PAPER\\Dataset\"  # Replace with your input folder path\n",
    "    output_folder = r\"C:\\Users\\xerom\\Documents\\CAPSTONE\\CONFERENCE_PAPER\\Dataset_gC\"  # Replace with your output folder path\n",
    "\n",
    "    process_images(input_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
