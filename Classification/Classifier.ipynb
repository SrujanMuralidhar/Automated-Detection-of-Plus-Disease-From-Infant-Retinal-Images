{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from adabelief_pytorch import AdaBelief\n",
    "from collections import Counter\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4970856163948774, 0.3660721661299467, 0.012605847830753192], \n",
    "                         [0.3098917880987543, 0.251007258041955, 0.08280670520288899])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Set Class Distribution:\n",
      "Class 'Pre Plus': 240 images\n",
      "Class 'Plus': 240 images\n",
      "Class 'No Plus': 240 images\n",
      "\n",
      "Validation Set Class Distribution:\n",
      "Class 'No Plus': 60 images\n",
      "Class 'Plus': 60 images\n",
      "Class 'Pre Plus': 60 images\n",
      "\n",
      "Classes and their encodings:\n",
      "Class 'No Plus': Encoding 0\n",
      "Class 'Plus': Encoding 1\n",
      "Class 'Pre Plus': Encoding 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have your transforms defined\n",
    "data_dir = 'output_thinned'  # Replace with your directory path\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "# Extract the targets (labels) from the dataset\n",
    "targets = np.array([y for _, y in dataset])\n",
    "\n",
    "# Stratified split to maintain class proportions\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get the train and validation indices\n",
    "train_indices, val_indices = next(splitter.split(np.zeros(len(targets)), targets))\n",
    "\n",
    "# Create train and validation subsets using the indices\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "# Create data loaders for train and validation sets\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "# Function to display the number of images per class\n",
    "def display_class_distribution(dataset, dataset_name):\n",
    "    class_counts = Counter([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "    print(f\"\\n{dataset_name} Class Distribution:\")\n",
    "    for class_idx, count in class_counts.items():\n",
    "        print(f\"Class '{dataset.dataset.classes[class_idx]}': {count} images\")\n",
    "\n",
    "# Display number of images in each class for train and validation sets\n",
    "display_class_distribution(train_dataset, 'Train Set')\n",
    "display_class_distribution(val_dataset, 'Validation Set')\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Classes and their encodings:\")\n",
    "for idx, class_name in enumerate(dataset.classes):\n",
    "    print(f\"Class '{class_name}': Encoding {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StagePenaltyLoss(nn.Module):\n",
    "#     def __init__(self, penalty_matrix):\n",
    "#         super(StagePenaltyLoss, self).__init__()\n",
    "#         self.penalty_matrix = torch.tensor(penalty_matrix, dtype=torch.float32).to(device=\"cuda\")\n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         # targets are assumed to be true class labels (integers)\n",
    "#         batch_size = predictions.size(0)\n",
    "#         n_classes = predictions.size(1)\n",
    "        \n",
    "#         # Apply softmax to the predictions to get probabilities\n",
    "#         probs = torch.softmax(predictions, dim=1)\n",
    "        \n",
    "#         # Gather penalties for each target class and predicted probability\n",
    "#         penalties = self.penalty_matrix[targets]\n",
    "        \n",
    "#         # Calculate the loss for each sample in the batch\n",
    "#         loss = torch.sum(penalties * probs, dim=1)\n",
    "        \n",
    "#         # Return mean loss over batch\n",
    "#         return loss.mean()\n",
    "    \n",
    "# # FVR < TAR < Stage 1 < Stage 2 < Stage 3\n",
    "\n",
    "# # Example usage:\n",
    "# penalty_matrix = [\n",
    "#     [0, 2, 3, 4, 1], # FVR\n",
    "#     [4, 0, 1, 2, 3], # Stage 1\n",
    "#     [4, 2, 0, 1, 3], # Stage 2\n",
    "#     [4, 1, 2, 0, 3], # Stage 3\n",
    "#     [4, 1, 2, 3, 0] # TAR\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# # Modify the last fully connected layer for the number of classes\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Check if GPU is available and move the model to GPU if possible\n",
    "# device = torch.device(\"cuda\")\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "# writer = SummaryWriter('runs/stage_classification_experiment_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "# # Modify the last fully connected layer for the number of classes\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # criterion = StagePenaltyLoss(penalty_matrix)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "# # optimizer = AdaBelief(model.parameters(), lr=1e-4, eps=1e-16, betas=(0.9, 0.999), weight_decay=1e-4, rectify=False)\n",
    "\n",
    "# # Check if GPU is available and move the model to GPU if possible\n",
    "# device = torch.device(\"cuda\")\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "# writer = SummaryWriter('runs/stage_classification_resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose the RegNet model architecture\n",
    "# model = models.regnet_y_8gf(weights=\"IMAGENET1K_V2\")  # Example: using regnet_y_8gf, can be adjusted\n",
    "\n",
    "# # Modify the last fully connected layer for the number of classes\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # criterion = StagePenaltyLoss(penalty_matrix)  # Use if you are implementing a custom loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "# # optimizer = AdaBelief(model.parameters(), lr=1e-4, eps=1e-16, betas=(0.9, 0.999), weight_decay=1e-4, rectify=False)\n",
    "\n",
    "# # Check if GPU is available and move the model to GPU if possible\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Initialize TensorBoard writer\n",
    "# writer = SummaryWriter('runs/stage_classification_regnet_y_8gf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the RegNet model architecture\n",
    "model = models.convnext_small(weights=\"IMAGENET1K_V1\")  # Example: using regnet_y_8gf, can be adjusted\n",
    "\n",
    "# Modify the last fully connected layer for the number of classes\n",
    "# model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = StagePenaltyLoss(penalty_matrix)  # Use if you are implementing a custom loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "# optimizer = AdaBelief(model.parameters(), lr=1e-4, eps=1e-16, betas=(0.9, 0.999), weight_decay=1e-4, rectify=False)\n",
    "\n",
    "# Check if GPU is available and move the model to GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter('runs/stage_classification_swinT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose the RegNet model architecture\n",
    "# model = models.regnet_y_8gf(weights=\"IMAGENET1K_V2\")  # Example: using regnet_y_8gf, can be adjusted\n",
    "\n",
    "# # Modify the last fully connected layer for the number of classes\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # criterion = StagePenaltyLoss(penalty_matrix)  # Use if you are implementing a custom loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "# # optimizer = AdaBelief(model.parameters(), lr=1e-4, eps=1e-16, betas=(0.9, 0.999), weight_decay=1e-4, rectify=False)\n",
    "\n",
    "# # Check if GPU is available and move the model to GPU if possible\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Initialize TensorBoard writer\n",
    "# writer = SummaryWriter('runs/stage_classification_regnet_y_8gf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            # Use tqdm to show progress bar for each phase\n",
    "            with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "                tepoch.set_description(f'{phase.capitalize()} Epoch {epoch+1}/{num_epochs}')\n",
    "                \n",
    "                # Iterate over data\n",
    "                for inputs, labels in tepoch:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward pass\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # Backward pass + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # Collect predictions and labels for Cohen's Kappa\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                    # Statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                    # Update tqdm progress bar with loss and accuracy\n",
    "                    tepoch.set_postfix(loss=running_loss / len(dataloaders[phase].dataset), \n",
    "                                       accuracy=running_corrects.float() / len(dataloaders[phase].dataset))\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            # print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Calculate Cohen's Kappa for validation phase\n",
    "            if phase == 'val':\n",
    "                kappa = cohen_kappa_score(all_preds, all_labels)\n",
    "                print(f'{phase.capitalize()} Cohen\\'s Kappa: {kappa:.4f}')\n",
    "\n",
    "            # Log metrics to TensorBoard\n",
    "            writer.add_scalar(f'{phase} Loss', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'{phase} Accuracy', epoch_acc, epoch)\n",
    "            if phase == 'val':\n",
    "                writer.add_scalar(f'{phase} Cohen\\'s Kappa', kappa, epoch)\n",
    "\n",
    "            # If it's the validation phase, save the best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), 'ConvNext_small_clahe.pth')\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_grad_cam import GradCAMPlusPlus\n",
    "# from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "# import numpy as np\n",
    "# from torchvision.utils import make_grid\n",
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "\n",
    "# def train_model(model, dataloaders, criterion, optimizer, device, writer, num_epochs=25):\n",
    "#     best_acc = 0.0\n",
    "#     grad_cam = GradCAMPlusPlus(model=model, target_layers=[model.features[-1]])  # Apply Grad-CAM to last block\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         # Each epoch has a training and validation phase\n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train()  # Set model to training mode\n",
    "#             else:\n",
    "#                 model.eval()   # Set model to evaluate mode\n",
    "\n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0\n",
    "\n",
    "#             # Wrapping DataLoader with tqdm for progress bar\n",
    "#             with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "#                 tepoch.set_description(f'{phase.capitalize()} Epoch {epoch+1}/{num_epochs}')\n",
    "                \n",
    "#                 # Iterate over data\n",
    "#                 for inputs, labels in tepoch:\n",
    "#                     inputs = inputs.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "\n",
    "#                     # Zero the parameter gradients\n",
    "#                     optimizer.zero_grad()\n",
    "\n",
    "#                     # Forward pass\n",
    "#                     with torch.set_grad_enabled(phase == 'train'):\n",
    "#                         outputs = model(inputs)\n",
    "#                         _, preds = torch.max(outputs, 1)\n",
    "#                         loss = criterion(outputs, labels)\n",
    "\n",
    "#                         # Backward pass + optimize only if in training phase\n",
    "#                         if phase == 'train':\n",
    "#                             loss.backward()\n",
    "#                             optimizer.step()\n",
    "\n",
    "#                     # Collect predictions and labels for later metrics calculation\n",
    "#                     running_loss += loss.item() * inputs.size(0)\n",
    "#                     running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#                     # Grad-CAM++ visualization for both phases\n",
    "#                     grad_cam_images = []\n",
    "#                     for i in range(inputs.size(0)):\n",
    "#                         # Convert to HWC format (height, width, channels) for Grad-CAM\n",
    "#                         input_np = inputs[i].cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "#                         # Normalize only for Grad-CAM computation (keeping original image as is)\n",
    "#                         input_normalized = input_np.astype(np.float32) / 255.0\n",
    "\n",
    "#                         # Apply Grad-CAM++ to compute the saliency map\n",
    "#                         grayscale_cam = grad_cam(input_tensor=inputs[i:i+1])\n",
    "\n",
    "#                         # Generate the heatmap, but retain the original image\n",
    "#                         cam_image = show_cam_on_image(input_normalized, grayscale_cam[0], use_rgb=True)\n",
    "\n",
    "#                         # Convert cam_image back to a tensor and permute it back to the required format\n",
    "#                         grad_cam_images.append(torch.tensor(cam_image).permute(2, 0, 1))\n",
    "\n",
    "#                     if grad_cam_images:\n",
    "#                         heatmap_grid = make_grid(torch.stack(grad_cam_images))\n",
    "#                         writer.add_image(f'{phase} Grad-CAM++', heatmap_grid, global_step=epoch)\n",
    "\n",
    "#                     # Update tqdm progress bar with loss and accuracy\n",
    "#                     tepoch.set_postfix(loss=running_loss / len(dataloaders[phase].dataset), \n",
    "#                                        accuracy=running_corrects.double() / len(dataloaders[phase].dataset))\n",
    "\n",
    "#             epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "#             epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "#             # Log metrics to TensorBoard\n",
    "#             writer.add_scalar(f'{phase} Loss', epoch_loss, epoch)\n",
    "#             writer.add_scalar(f'{phase} Accuracy', epoch_acc, epoch)\n",
    "\n",
    "#             print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#             # Save best model based on validation accuracy\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 torch.save(model.state_dict(), 'RegNet.pth')\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_model(model, criterion, optimizer, num_epochs=50)\n",
    "# model = train_model(model, dataloaders, criterion, optimizer, device, writer, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_embeddings(dataloader, model):\n",
    "#     model.eval()\n",
    "#     embeddings = []\n",
    "#     labels_list = []\n",
    "#     image_list = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in dataloader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             # Forward pass through all layers except the final fully connected (fc) layer\n",
    "#             features = model.conv1(inputs)\n",
    "#             features = model.bn1(features)\n",
    "#             features = model.relu(features)\n",
    "#             features = model.maxpool(features)\n",
    "#             features = model.layer1(features)\n",
    "#             features = model.layer2(features)\n",
    "#             features = model.layer3(features)\n",
    "#             features = model.layer4(features)\n",
    "#             features = model.avgpool(features)\n",
    "#             features = torch.flatten(features, 1)  # Flatten to (batch_size, feature_size)\n",
    "\n",
    "#             embeddings.append(features.cpu())  # Store the features/embeddings\n",
    "#             labels_list.append(labels.cpu())   # Store corresponding labels\n",
    "#             image_list.append(inputs.cpu())    # Save images as numpy arrays\n",
    "\n",
    "#     return torch.cat(embeddings), torch.cat(labels_list), torch.cat(image_list)\n",
    "\n",
    "\n",
    "# # Extract embeddings, labels, and images\n",
    "# embeddings, labels, images = extract_embeddings(dataloaders['val'], model)\n",
    "\n",
    "# # Log embeddings to TensorBoard projector\n",
    "# def log_embeddings_to_projector(writer, embeddings, labels, images, class_names):\n",
    "#     writer.add_embedding(embeddings, metadata=labels, label_img=images)\n",
    "    \n",
    "#     # Save class names as a separate metadata file\n",
    "#     class_metadata_path = os.path.join('runs', 'class_metadata.tsv')\n",
    "#     with open(class_metadata_path, 'w') as f:\n",
    "#         for label in class_names:\n",
    "#             f.write(f'{label}\\n')\n",
    "\n",
    "#     # Add projector config\n",
    "#     writer.add_embedding(embeddings, metadata=labels.tolist(), label_img=images)\n",
    "\n",
    "# # Log embeddings to TensorBoard projector\n",
    "# log_embeddings_to_projector(writer, embeddings, labels, images, dataset.classes)\n",
    "\n",
    "# # Close the TensorBoard writer after training is complete\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84031cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444, Precision: 0.9453, Recall: 0.9444, F1 Score: 0.9437\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "# Function to display confusion matrix\n",
    "def plot_confusion_matrix(conf_matrix, class_names):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'model' is your trained model and 'dataloaders['val']' is your test/validation dataloader.\n",
    "device = torch.device(\"cuda\")\n",
    "model.load_state_dict(torch.load(r'ConvNext_small_clahe.pth', map_location=torch.device('cuda')))\n",
    "\n",
    "accuracy, precision, recall, f1, conf_matrix = evaluate_model(model, dataloaders['val'], device)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(conf_matrix, dataset.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stores the mis-classified images to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# # Function to evaluate the model on the validation set and save misclassified images' details\n",
    "# def evaluate_model_with_misclassifications(model, dataloader, device, dataset):\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "#     all_labels = []\n",
    "#     all_preds = []\n",
    "#     misclassified_data = []\n",
    "\n",
    "#     with torch.no_grad():  # Disable gradient calculation\n",
    "#         for inputs, labels, paths in dataloader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "            \n",
    "#             # Check for misclassifications and collect their details\n",
    "#             for i in range(len(labels)):\n",
    "#                 if preds[i] != labels[i]:  # Misclassified\n",
    "#                     image_path = paths[i]\n",
    "#                     original_label = dataset.classes[labels[i].item()]\n",
    "#                     predicted_label = dataset.classes[preds[i].item()]\n",
    "#                     misclassified_data.append([os.path.basename(image_path), original_label, predicted_label])\n",
    "\n",
    "#     # Convert lists to numpy arrays\n",
    "#     all_labels = np.array(all_labels)\n",
    "#     all_preds = np.array(all_preds)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     accuracy = accuracy_score(all_labels, all_preds)\n",
    "#     precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "#     recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "#     f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "#     # Confusion matrix\n",
    "#     conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "#     # Save misclassified data to CSV\n",
    "#     df = pd.DataFrame(misclassified_data, columns=['Image Name', 'Original Label', 'Predicted Label'])\n",
    "#     df.to_csv('misclassified_images.csv', index=False)\n",
    "    \n",
    "#     return accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "# # Example usage:\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.load_state_dict(torch.load('ResNet50_AllStagesSuperposed_TL.pth', map_location=device))\n",
    "# model.to(device)  # Ensure model is on the correct device\n",
    "\n",
    "# # Custom dataset class\n",
    "# class CustomImageFolder(datasets.ImageFolder):\n",
    "#     def __getitem__(self, index):\n",
    "#         original_tuple = super().__getitem__(index)\n",
    "#         path = self.imgs[index][0]\n",
    "#         return (*original_tuple, path)\n",
    "\n",
    "# # Load only validation dataset\n",
    "# data_dir = 'Data_superposed'  # Replace with your directory path\n",
    "# dataset_with_paths = CustomImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "# # Create DataLoader for the validation set only\n",
    "# dataloaders_with_paths = {\n",
    "#     'val': DataLoader(dataset_with_paths, batch_size=32, shuffle=False, num_workers=0)  # Change num_workers for debugging\n",
    "# }\n",
    "\n",
    "# # Evaluate the model on the validation dataset\n",
    "# accuracy, precision, recall, f1, conf_matrix = evaluate_model_with_misclassifications(model, dataloaders_with_paths['val'], device, dataset_with_paths)\n",
    "\n",
    "# # Print metrics\n",
    "# print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "# # Assuming plot_confusion_matrix is defined\n",
    "# plot_confusion_matrix(conf_matrix, dataset_with_paths.classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# # Define evaluate_metrics function\n",
    "# def evaluate_metrics(preds, labels):\n",
    "#     metrics = {}\n",
    "#     metrics['accuracy'] = accuracy_score(labels, preds)\n",
    "#     metrics['precision'] = precision_score(labels, preds, average='weighted')  # Use 'macro' for class balance\n",
    "#     metrics['recall'] = recall_score(labels, preds, average='weighted')\n",
    "#     metrics['f1_score'] = f1_score(labels, preds, average='weighted')\n",
    "#     return metrics\n",
    "\n",
    "\n",
    "# # Define k-fold cross-validation function\n",
    "# def k_fold_cross_validation(model, dataset, k=5, batch_size=32, device='cuda'):\n",
    "#     # Initialize KFold with k splits\n",
    "#     kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "#     fold_metrics = {\n",
    "#         'accuracy': [],\n",
    "#         'precision': [],\n",
    "#         'recall': [],\n",
    "#         'f1_score': []\n",
    "#     }\n",
    "    \n",
    "#     for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "#         print(f'Fold {fold + 1}/{k}')\n",
    "        \n",
    "#         # Define subsets for training and validation for this fold\n",
    "#         train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "#         val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "        \n",
    "#         # Create DataLoaders\n",
    "#         train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "#         val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "#         # Reset model weights for each fold\n",
    "#         model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "        \n",
    "#         # Set up optimizer and loss function\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#         criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "#         # Training loop for the current fold\n",
    "#         for epoch in range(10):  #Ensure num_epochs is defined\n",
    "#             model.train()\n",
    "#             for images, labels in train_loader:\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "        \n",
    "#         # Validation loop\n",
    "#         model.eval()\n",
    "#         metrics = {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "        \n",
    "#         # Use tqdm to track validation progress\n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in tqdm(val_loader, desc=f'Validating Fold {fold + 1}'):\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 outputs = model(images)\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "#                 # Assuming evaluate_metrics function calculates metrics per batch\n",
    "#                 batch_metrics = evaluate_metrics(preds.cpu(), labels.cpu())\n",
    "                \n",
    "#                 # Sum metrics for this fold\n",
    "#                 for key in metrics:\n",
    "#                     metrics[key] += batch_metrics[key]\n",
    "        \n",
    "#         # Average metrics for the fold\n",
    "#         for key in metrics:\n",
    "#             metrics[key] /= len(val_loader)\n",
    "#             fold_metrics[key].append(metrics[key])\n",
    "    \n",
    "#     # Calculate and return the average metrics across all folds\n",
    "#     avg_metrics = {key: sum(values) / k for key, values in fold_metrics.items()}\n",
    "#     return avg_metrics\n",
    "\n",
    "# # Usage example (replace model and dataset with your specific instances):\n",
    "# avg_metrics = k_fold_cross_validation(model, dataloaders['val'], k=5, batch_size=4, device='cuda')\n",
    "# print(avg_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "================================\n",
      "Accuracy: 0.8889, Precision: 0.8898, Recall: 0.8889, F1 Score: 0.8873\n",
      "FOLD 2\n",
      "================================\n",
      "Accuracy: 0.8889, Precision: 0.8897, Recall: 0.8889, F1 Score: 0.8872\n",
      "FOLD 3\n",
      "================================\n",
      "Accuracy: 0.9056, Precision: 0.9083, Recall: 0.9056, F1 Score: 0.9040\n",
      "================================\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 3 FOLDS\n",
      "Average Accuracy: 0.8944  0.0079\n",
      "Average Precision: 0.8960  0.0087\n",
      "Average Recall: 0.8944  0.0079\n",
      "Average F1 Score: 0.8928  0.0079\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Parameters\n",
    "# k_folds = 3\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Prepare k-fold cross-validation\n",
    "# kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# # Store metrics for each fold\n",
    "# fold_accuracies = []\n",
    "# fold_precisions = []\n",
    "# fold_recalls = []\n",
    "# fold_f1_scores = []\n",
    "\n",
    "# # Loop through each fold\n",
    "# for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "#     print(f\"FOLD {fold + 1}\")\n",
    "#     print(\"================================\")\n",
    "\n",
    "#     # Split data for this fold\n",
    "#     val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "#     val_loader = dataloaders['val']\n",
    "\n",
    "#     # Load stored model\n",
    "#     model.load_state_dict(torch.load(r'ResNet_Models\\ResNet50_3StagesSuperposed_TL.pth', map_location=torch.device('cuda'))) # Replace with your model's path\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "\n",
    "#     # Validation loop\n",
    "#     val_preds = []\n",
    "#     val_labels = []\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in val_loader:\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             val_preds.extend(preds.cpu().numpy())\n",
    "#             val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     # Compute metrics for this fold\n",
    "#     accuracy = accuracy_score(val_labels, val_preds)\n",
    "#     precision = precision_score(val_labels, val_preds, average='weighted')\n",
    "#     recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "#     f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "#     print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "#     fold_accuracies.append(accuracy)\n",
    "#     fold_precisions.append(precision)\n",
    "#     fold_recalls.append(recall)\n",
    "#     fold_f1_scores.append(f1)\n",
    "\n",
    "# # Display average metrics\n",
    "# print(\"================================\")\n",
    "# print(\"K-FOLD CROSS VALIDATION RESULTS FOR {} FOLDS\".format(k_folds))\n",
    "# print(\"Average Accuracy: {:.4f}\".format(np.mean(fold_accuracies)))\n",
    "# print(\"Average Precision: {:.4f}\".format(np.mean(fold_precisions)))\n",
    "# print(\"Average Recall: {:.4f}\".format(np.mean(fold_recalls)))\n",
    "# print(\"Average F1 Score: {:.4f}\".format(np.mean(fold_f1_scores)))\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Parameters\n",
    "k_folds = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare k-fold cross-validation\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "    print(f\"FOLD {fold + 1}\")\n",
    "    print(\"================================\")\n",
    "\n",
    "    # Split data for this fold\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    val_loader = dataloaders['val']  # Make sure to create a new DataLoader for validation\n",
    "\n",
    "    # Load stored model\n",
    "    model.load_state_dict(torch.load(r'RegNet.pth', map_location=device))  # Replace with your model's path\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Validation loop\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute metrics for this fold\n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "    precision = precision_score(val_labels, val_preds, average='weighted')\n",
    "    recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "    f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Display average metrics and their standard deviations\n",
    "print(\"================================\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS FOR {} FOLDS\".format(k_folds))\n",
    "print(\"Average Accuracy: {:.4f}  {:.4f}\".format(np.mean(fold_accuracies), np.std(fold_accuracies)))\n",
    "print(\"Average Precision: {:.4f}  {:.4f}\".format(np.mean(fold_precisions), np.std(fold_precisions)))\n",
    "print(\"Average Recall: {:.4f}  {:.4f}\".format(np.mean(fold_recalls), np.std(fold_recalls)))\n",
    "print(\"Average F1 Score: {:.4f}  {:.4f}\".format(np.mean(fold_f1_scores), np.std(fold_f1_scores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
